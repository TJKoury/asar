{"version":3,"sources":["webpack:///webpack/bootstrap af527b72fe4ae4097f0a","webpack:///external \"fs\"","webpack:///external \"path\"","webpack:///external \"mkdirp\"","webpack:///./lib/filesystem.js","webpack:///./lib/asar.js","webpack:///external \"minimatch\"","webpack:///external \"tmp\"","webpack:///external \"cuint\"","webpack:///./lib/disk.js","webpack:///external \"chromium-pickle-js\"","webpack:///./lib/crawlfs.js","webpack:///external \"glob\"","webpack:///./lib/snapshot.js","webpack:///external \"mksnapshot\"","webpack:///external \"vm\""],"names":[],"mappings":";;AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;AC7DA,+B;;;;;;ACAA,iC;;;;;;ACAA,mC;;;;;;;ACAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,2BAA2B,EAAE;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA,yBAAyB,EAAE;AAC3B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;;;;;;;;ACtJA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,OAAO;AAClB,WAAW,MAAM;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,mBAAmB,uBAAuB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8DAA8D;AAC9D;;AAEA;AACA;;AAEA,+BAA+B,WAAW;AAC1C,gBAAgB;AAChB;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,6CAA6C,0CAA0C;AACvF;AACA;AACA;AACA;AACA,6DAA6D,cAAc;AAC3E;AACA;AACA;;AAEA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,iCAAiC;AACjC;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,qCAAqC,kCAAkC;AACvE,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B,0BAA0B;AAC1B,kCAAkC;AAClC,cAAc;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,gBAAgB;AAC9E;AACA;AACA;AACA;AACA;AACA,oBAAoB,yCAAyC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,kBAAkB;AAClB;AACA,oBAAoB;AACpB;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP,KAAK;AACL;;AAEA;;AAEA;AACA,gBAAgB;;AAEhB;AACA;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;;;;;;;ACzNA,sC;;;;;;ACAA,gC;;;;;;ACAA,kC;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,gDAAgD,mBAAmB;AACnE;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,wBAAwB,KAAK;AAC7B,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,sBAAsB,aAAa;AACnC;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,UAAU;AACV;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,uBAAuB;AACvB;AACA;AACA,0CAA0C,eAAe;AACzD,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzIA,+C;;;;;;;ACAA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA,8BAA8B;AAC9B,OAAO;AACP,8BAA8B;AAC9B,OAAO;AACP,8BAA8B;AAC9B;AACA;AACA;AACA,GAAG;AACH;;;;;;;ACpBA,iC;;;;;;;ACAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sEAAsE,GAAG,OAAO,IAAI,EAAE;AACtF;;AAEA;AACA,6CAA6C;AAC7C;AACA;AACA,oBAAoB,SAAS,KAAK,KAAK;AACvC;AACA,eAAe;AACf;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,2BAA2B;AACnF;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,mEAAmE;AACnE;AACA;AACA;;AAEA;;;;;;;AC7DA,uC;;;;;;ACAA,+B","file":"asar.lib.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 4);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap af527b72fe4ae4097f0a","module.exports = require(\"fs\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"fs\"\n// module id = 0\n// module chunks = 0","module.exports = require(\"path\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"path\"\n// module id = 1\n// module chunks = 0","module.exports = require(\"mkdirp\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"mkdirp\"\n// module id = 2\n// module chunks = 0","'use strict'\nconst fs = require('fs')\nconst path = require('path')\nconst tmp = require('tmp')\nconst UINT64 = require('cuint').UINT64\n\nclass Filesystem {\n  constructor (src) {\n    this.src = path.resolve(src)\n    this.header = {files: {}}\n    this.offset = UINT64(0)\n  }\n\n  searchNodeFromDirectory (p) {\n    let json = this.header\n    const dirs = p.split(path.sep)\n    for (const dir of dirs) {\n      if (dir !== '.') {\n        json = json.files[dir]\n      }\n    }\n    return json\n  }\n\n  searchNodeFromPath (p) {\n    p = path.relative(this.src, p)\n    if (!p) { return this.header }\n    const name = path.basename(p)\n    const node = this.searchNodeFromDirectory(path.dirname(p))\n    if (node.files == null) {\n      node.files = {}\n    }\n    if (node.files[name] == null) {\n      node.files[name] = {}\n    }\n    return node.files[name]\n  }\n\n  insertDirectory (p, shouldUnpack) {\n    const node = this.searchNodeFromPath(p)\n    if (shouldUnpack) {\n      node.unpacked = shouldUnpack\n    }\n    node.files = {}\n    return node.files\n  }\n\n  insertFile (p, shouldUnpack, file, options, callback) {\n    const dirNode = this.searchNodeFromPath(path.dirname(p))\n    const node = this.searchNodeFromPath(p)\n    if (shouldUnpack || dirNode.unpacked) {\n      node.size = file.stat.size\n      node.unpacked = true\n      process.nextTick(callback)\n      return\n    }\n\n    const handler = () => {\n      const size = file.transformed ? file.transformed.stat.size : file.stat.size\n\n      // JavaScript can not precisely present integers >= UINT32_MAX.\n      if (size > 4294967295) {\n        throw new Error(`${p}: file size can not be larger than 4.2GB`)\n      }\n\n      node.size = size\n      node.offset = this.offset.toString()\n      if (process.platform !== 'win32' && (file.stat.mode & 0o100)) {\n        node.executable = true\n      }\n      this.offset.add(UINT64(size))\n\n      return callback()\n    }\n\n    const tr = options.transform && options.transform(p)\n    if (tr) {\n      return tmp.file(function (err, path) {\n        if (err) { return handler() }\n        const out = fs.createWriteStream(path)\n        const stream = fs.createReadStream(p)\n\n        stream.pipe(tr).pipe(out)\n        return tr.on('end', function () {\n          file.transformed = {\n            path,\n            stat: fs.lstatSync(path)\n          }\n          return handler()\n        })\n      })\n    } else {\n      return process.nextTick(handler)\n    }\n  }\n\n  insertLink (p, stat) {\n    const link = path.relative(fs.realpathSync(this.src), fs.realpathSync(p))\n    if (link.substr(0, 2) === '..') {\n      throw new Error(`${p}: file links out of the package`)\n    }\n    const node = this.searchNodeFromPath(p)\n    node.link = link\n    return link\n  }\n\n  listFiles () {\n    const files = []\n    const fillFilesFromHeader = function (p, json) {\n      if (!json.files) {\n        return\n      }\n      return (() => {\n        const result = []\n        for (const f in json.files) {\n          const fullPath = path.join(p, f)\n          files.push(fullPath)\n          result.push(fillFilesFromHeader(fullPath, json.files[f]))\n        }\n        return result\n      })()\n    }\n\n    fillFilesFromHeader('/', this.header)\n    return files\n  }\n\n  getNode (p) {\n    const node = this.searchNodeFromDirectory(path.dirname(p))\n    const name = path.basename(p)\n    if (name) {\n      return node.files[name]\n    } else {\n      return node\n    }\n  }\n\n  getFile (p, followLinks) {\n    followLinks = typeof followLinks === 'undefined' ? true : followLinks\n    const info = this.getNode(p)\n\n    // if followLinks is false we don't resolve symlinks\n    if (info.link && followLinks) {\n      return this.getFile(info.link)\n    } else {\n      return info\n    }\n  }\n}\n\nmodule.exports = Filesystem\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./lib/filesystem.js\n// module id = 3\n// module chunks = 0","'use strict'\nconst fs = require('fs')\nconst path = require('path')\nconst minimatch = require('minimatch')\nconst mkdirp = require('mkdirp')\n\nconst Filesystem = require('./filesystem')\nconst disk = require('./disk')\nconst crawlFilesystem = require('./crawlfs')\nconst createSnapshot = require('./snapshot')\n\n// Return whether or not a directory should be excluded from packing due to\n// \"--unpack-dir\" option\n//\n// @param {string} path - diretory path to check\n// @param {string} pattern - literal prefix [for backward compatibility] or glob pattern\n// @param {array} unpackDirs - Array of directory paths previously marked as unpacked\n//\nconst isUnpackDir = function (path, pattern, unpackDirs) {\n  if (path.indexOf(pattern) === 0 || minimatch(path, pattern)) {\n    if (unpackDirs.indexOf(path) === -1) {\n      unpackDirs.push(path)\n    }\n    return true\n  } else {\n    for (let i = 0; i < unpackDirs.length; i++) {\n      if (path.indexOf(unpackDirs[i]) === 0) {\n        return true\n      }\n    }\n    return false\n  }\n}\n\nmodule.exports.createPackage = function (src, dest, callback) {\n  return module.exports.createPackageWithOptions(src, dest, {}, callback)\n}\n\nmodule.exports.createPackageWithOptions = function (src, dest, options, callback) {\n  const dot = typeof options.dot === 'undefined' ? true : options.dot\n\n  return crawlFilesystem(src, { dot: dot }, function (error, filenames, metadata) {\n    if (error) { return callback(error) }\n    module.exports.createPackageFromFiles(src, dest, filenames, metadata, options, callback)\n  })\n}\n\n/*\ncreatePackageFromFiles - Create an asar-archive from a list of filenames\nsrc: Base path. All files are relative to this.\ndest: Archive filename (& path).\nfilenames: Array of filenames relative to src.\nmetadata: Object with filenames as keys and {type='directory|file|link', stat: fs.stat} as values. (Optional)\noptions: The options.\ncallback: The callback function. Accepts (err).\n*/\nmodule.exports.createPackageFromFiles = function (src, dest, filenames, metadata, options, callback) {\n  if (typeof metadata === 'undefined' || metadata === null) { metadata = {} }\n  const filesystem = new Filesystem(src)\n  const files = []\n  const unpackDirs = []\n\n  let filenamesSorted = []\n  if (options.ordering) {\n    const orderingFiles = fs.readFileSync(options.ordering).toString().split('\\n').map(function (line) {\n      if (line.includes(':')) { line = line.split(':').pop() }\n      line = line.trim()\n      if (line.startsWith('/')) { line = line.slice(1) }\n      return line\n    })\n\n    const ordering = []\n    for (const file of orderingFiles) {\n      const pathComponents = file.split(path.sep)\n      let str = src\n      for (const pathComponent of pathComponents) {\n        str = path.join(str, pathComponent)\n        ordering.push(str)\n      }\n    }\n\n    let missing = 0\n    const total = filenames.length\n\n    for (const file of ordering) {\n      if (!filenamesSorted.includes(file) && filenames.includes(file)) {\n        filenamesSorted.push(file)\n      }\n    }\n\n    for (const file of filenames) {\n      if (!filenamesSorted.includes(file)) {\n        filenamesSorted.push(file)\n        missing += 1\n      }\n    }\n\n    console.log(`Ordering file has ${((total - missing) / total) * 100}% coverage.`)\n  } else {\n    filenamesSorted = filenames\n  }\n\n  const handleFile = function (filename, done) {\n    let file = metadata[filename]\n    let type\n    if (!file) {\n      const stat = fs.lstatSync(filename)\n      if (stat.isDirectory()) { type = 'directory' }\n      if (stat.isFile()) { type = 'file' }\n      if (stat.isSymbolicLink()) { type = 'link' }\n      file = {stat, type}\n    }\n\n    let shouldUnpack\n    switch (file.type) {\n      case 'directory':\n        shouldUnpack = options.unpackDir\n          ? isUnpackDir(path.relative(src, filename), options.unpackDir, unpackDirs)\n          : false\n        filesystem.insertDirectory(filename, shouldUnpack)\n        break\n      case 'file':\n        shouldUnpack = false\n        if (options.unpack) {\n          shouldUnpack = minimatch(filename, options.unpack, {matchBase: true})\n        }\n        if (!shouldUnpack && options.unpackDir) {\n          const dirName = path.relative(src, path.dirname(filename))\n          shouldUnpack = isUnpackDir(dirName, options.unpackDir, unpackDirs)\n        }\n        files.push({filename: filename, unpack: shouldUnpack})\n        filesystem.insertFile(filename, shouldUnpack, file, options, done)\n        return\n      case 'link':\n        filesystem.insertLink(filename, file.stat)\n        break\n    }\n    return process.nextTick(done)\n  }\n\n  const insertsDone = function () {\n    return mkdirp(path.dirname(dest), function (error) {\n      if (error) { return callback(error) }\n      return disk.writeFilesystem(dest, filesystem, files, metadata, function (error) {\n        if (error) { return callback(error) }\n        if (options.snapshot) {\n          return createSnapshot(src, dest, filenames, metadata, options, callback)\n        } else {\n          return callback(null)\n        }\n      })\n    })\n  }\n\n  const names = filenamesSorted.slice()\n\n  const next = function (name) {\n    if (!name) { return insertsDone() }\n\n    return handleFile(name, function () {\n      return next(names.shift())\n    })\n  }\n\n  return next(names.shift())\n}\n\nmodule.exports.statFile = function (archive, filename, followLinks) {\n  const filesystem = disk.readFilesystemSync(archive)\n  return filesystem.getFile(filename, followLinks)\n}\n\nmodule.exports.listPackage = function (archive) {\n  return disk.readFilesystemSync(archive).listFiles()\n}\n\nmodule.exports.extractFile = function (archive, filename) {\n  const filesystem = disk.readFilesystemSync(archive)\n  return disk.readFileSync(filesystem, filename, filesystem.getFile(filename))\n}\n\nmodule.exports.extractAll = function (archive, dest) {\n  const filesystem = disk.readFilesystemSync(archive)\n  const filenames = filesystem.listFiles()\n\n  // under windows just extract links as regular files\n  const followLinks = process.platform === 'win32'\n\n  // create destination directory\n  mkdirp.sync(dest)\n\n  return filenames.map((filename) => {\n    filename = filename.substr(1)  // get rid of leading slash\n    const destFilename = path.join(dest, filename)\n    const file = filesystem.getFile(filename, followLinks)\n    if (file.files) {\n      // it's a directory, create it and continue with the next entry\n      mkdirp.sync(destFilename)\n    } else if (file.link) {\n      // it's a symlink, create a symlink\n      const linkSrcPath = path.dirname(path.join(dest, file.link))\n      const linkDestPath = path.dirname(destFilename)\n      const relativePath = path.relative(linkDestPath, linkSrcPath);\n      // try to delete output file, because we can't overwrite a link\n      (() => {\n        try {\n          fs.unlinkSync(destFilename)\n        } catch (error) {}\n      })()\n      const linkTo = path.join(relativePath, path.basename(file.link))\n      fs.symlinkSync(linkTo, destFilename)\n    } else {\n      // it's a file, extract it\n      const content = disk.readFileSync(filesystem, filename, file)\n      fs.writeFileSync(destFilename, content)\n    }\n  })\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./lib/asar.js\n// module id = 4\n// module chunks = 0","module.exports = require(\"minimatch\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"minimatch\"\n// module id = 5\n// module chunks = 0","module.exports = require(\"tmp\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"tmp\"\n// module id = 6\n// module chunks = 0","module.exports = require(\"cuint\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"cuint\"\n// module id = 7\n// module chunks = 0","'use strict'\nconst fs = require('fs')\nconst path = require('path')\nconst mkdirp = require('mkdirp')\nconst pickle = require('chromium-pickle-js')\nconst Filesystem = require('./filesystem')\nconst filesystemCache = {}\n\nconst copyFileToSync = function (dest, src, filename) {\n  const srcFile = path.join(src, filename)\n  const targetFile = path.join(dest, filename)\n\n  const content = fs.readFileSync(srcFile)\n  const stats = fs.statSync(srcFile)\n  mkdirp.sync(path.dirname(targetFile))\n  return fs.writeFileSync(targetFile, content, { mode: stats.mode })\n}\n\nconst writeFileListToStream = function (dest, filesystem, out, list, metadata, callback) {\n  if (list.length === 0) {\n    out.end()\n    return callback(null)\n  }\n\n  const file = list[0]\n  if (file.unpack) {\n    // the file should not be packed into archive.\n    const filename = path.relative(filesystem.src, file.filename)\n    try {\n      copyFileToSync(`${dest}.unpacked`, filesystem.src, filename)\n    } catch (error) {\n      return callback(error)\n    }\n    return writeFileListToStream(dest, filesystem, out, list.slice(1), metadata, callback)\n  } else {\n    const tr = metadata[file.filename].transformed\n    const stream = fs.createReadStream((tr ? tr.path : file.filename))\n    stream.pipe(out, { end: false })\n    stream.on('error', callback)\n    return stream.on('end', function () {\n      return writeFileListToStream(dest, filesystem, out, list.slice(1), metadata, callback)\n    })\n  }\n}\n\nmodule.exports.writeFilesystem = function (dest, filesystem, files, metadata, callback) {\n  let sizeBuf\n  let headerBuf\n  try {\n    const headerPickle = pickle.createEmpty()\n    headerPickle.writeString(JSON.stringify(filesystem.header))\n    headerBuf = headerPickle.toBuffer()\n\n    const sizePickle = pickle.createEmpty()\n    sizePickle.writeUInt32(headerBuf.length)\n    sizeBuf = sizePickle.toBuffer()\n  } catch (error) {\n    return callback(error)\n  }\n\n  const out = fs.createWriteStream(dest)\n  out.on('error', callback)\n  out.write(sizeBuf)\n  return out.write(headerBuf, function () {\n    return writeFileListToStream(dest, filesystem, out, files, metadata, callback)\n  })\n}\n\nmodule.exports.readArchiveHeaderSync = function (archive) {\n  const fd = fs.openSync(archive, 'r')\n  let size\n  let headerBuf\n  try {\n    const sizeBuf = new Buffer(8)\n    const startPos = this.checkFileSignature(archive, null)\n\n    if (fs.readSync(fd, sizeBuf, 0, 8, startPos) !== 8) {\n      throw new Error('Unable to read header size')\n    }\n\n    const sizePickle = pickle.createFromBuffer(sizeBuf)\n    size = sizePickle.createIterator().readUInt32()\n    headerBuf = new Buffer(size)\n    if (fs.readSync(fd, headerBuf, 0, size, startPos + 8) !== size) {\n      throw new Error('Unable to read header')\n    }\n  } finally {\n    fs.closeSync(fd)\n  }\n  const headerPickle = pickle.createFromBuffer(headerBuf)\n  const header = headerPickle.createIterator().readString()\n  return { header: JSON.parse(header), headerSize: size }\n}\n\nmodule.exports.readFilesystemSync = function (archive) {\n  if (!filesystemCache[archive]) {\n    const header = this.readArchiveHeaderSync(archive)\n    const filesystem = new Filesystem(archive)\n    filesystem.header = header.header\n    filesystem.headerSize = header.headerSize\n    filesystemCache[archive] = filesystem\n  }\n  return filesystemCache[archive]\n}\n\nmodule.exports.readFileSync = function (filesystem, filename, info) {\n  let buffer = new Buffer(info.size)\n  if (info.size <= 0) { return buffer }\n  if (info.unpacked) {\n    // it's an unpacked file, copy it.\n    buffer = fs.readFileSync(path.join(`${filesystem.src}.unpacked`, filename))\n  } else {\n    // Node throws an exception when reading 0 bytes into a 0-size buffer,\n    // so we short-circuit the read in this case.\n    const fd = fs.openSync(filesystem.src, 'r')\n    try {\n      const offset = 8 + filesystem.headerSize + parseInt(info.offset)\n      fs.readSync(fd, buffer, 0, info.size, offset)\n    } finally {\n      fs.closeSync(fd)\n    }\n  }\n  return buffer\n}\n\nmodule.exports.checkFileSignature = function (archive, defaultPosition) {\n  const fd = fs.openSync(archive, 'r')\n  let endCapSize = 12\n  let _b = Buffer.alloc(endCapSize)\n  let size = fs.fstatSync(fd).size\n  if (size > endCapSize) {\n    fs.readSync(fd, _b, 0, endCapSize, size - endCapSize)\n    let [_size, _shift, _result] = [_b.readUIntLE(0, 6), _b.readUIntLE(6, 1), _b.readUIntLE(7, 5)]\n    fs.closeSync(fd)\n    let _start = (size - _size - endCapSize)\n    return (_result === _size >> _shift) ? _start : defaultPosition\n  }\n}\n\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./lib/disk.js\n// module id = 8\n// module chunks = 0","module.exports = require(\"chromium-pickle-js\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"chromium-pickle-js\"\n// module id = 9\n// module chunks = 0","'use strict'\nconst fs = require('fs')\nconst glob = require('glob')\n\nmodule.exports = function (dir, options, callback) {\n  const metadata = {}\n  return glob(dir + '/**/*', options, function (error, filenames) {\n    if (error) { return callback(error) }\n    for (const filename of filenames) {\n      const stat = fs.lstatSync(filename)\n      if (stat.isFile()) {\n        metadata[filename] = {type: 'file', stat: stat}\n      } else if (stat.isDirectory()) {\n        metadata[filename] = {type: 'directory', stat: stat}\n      } else if (stat.isSymbolicLink()) {\n        metadata[filename] = {type: 'link', stat: stat}\n      }\n    }\n    return callback(null, filenames, metadata)\n  })\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./lib/crawlfs.js\n// module id = 10\n// module chunks = 0","module.exports = require(\"glob\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"glob\"\n// module id = 11\n// module chunks = 0","'use strict'\nconst fs = require('fs')\nconst path = require('path')\nconst mksnapshot = require('mksnapshot')\nconst vm = require('vm')\n\nconst stripBOM = function (content) {\n  if (content.charCodeAt(0) === 0xFEFF) {\n    content = content.slice(1)\n  }\n  return content\n}\n\nconst wrapModuleCode = function (script) {\n  script = script.replace(/^#!.*/, '')\n  return `(function(exports, require, module, __filename, __dirname) { ${script} \\n});`\n}\n\nconst dumpObjectToJS = function (content) {\n  let result = 'var __ATOM_SHELL_SNAPSHOT = {\\n'\n  for (const filename in content) {\n    const func = content[filename].toString()\n    result += `  '${filename}': ${func},\\n`\n  }\n  result += '};\\n'\n  return result\n}\n\nconst createSnapshot = function (src, dest, filenames, metadata, options, callback) {\n  const content = {}\n  try {\n    src = path.resolve(src)\n    for (const filename of filenames) {\n      const file = metadata[filename]\n      if ((file.type === 'file' || file.type === 'link') && filename.substr(-3) === '.js') {\n        const script = wrapModuleCode(stripBOM(fs.readFileSync(filename, 'utf8')))\n        const relativeFilename = path.relative(src, filename)\n        try {\n          const compiled = vm.runInThisContext(script, {filename: relativeFilename})\n          content[relativeFilename] = compiled\n        } catch (error) {\n          console.error('Ignoring ' + relativeFilename + ' for ' + error.name)\n        }\n      }\n    }\n  } catch (error) {\n    return callback(error)\n  }\n\n  // run mksnapshot\n  const str = dumpObjectToJS(content)\n  const version = options.version\n  const arch = options.arch\n  const builddir = options.builddir\n  let snapshotdir = options.snapshotdir\n\n  if (typeof snapshotdir === 'undefined' || snapshotdir === null) { snapshotdir = path.dirname(dest) }\n  const target = path.resolve(snapshotdir, 'snapshot_blob.bin')\n  return mksnapshot(str, target, version, arch, builddir, callback)\n}\n\nmodule.exports = createSnapshot\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./lib/snapshot.js\n// module id = 12\n// module chunks = 0","module.exports = require(\"mksnapshot\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"mksnapshot\"\n// module id = 13\n// module chunks = 0","module.exports = require(\"vm\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"vm\"\n// module id = 14\n// module chunks = 0"],"sourceRoot":""}